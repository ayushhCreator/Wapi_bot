# ðŸ—ï¸ WapiBot V2 Architecture

## **Production-Ready, LLM-Resilient, Visual Workflow System**

**Date:** 2025-12-24
**Status:** Design Phase
**Goal:** Eliminate orchestration hell, ensure LLM resilience, enable visual editing

---

## ðŸ“‹ DESIGN PRINCIPLES

### 1. **LLM Resilience (CRITICAL)**

**Problem:** Junior broke demo when Ollama failed â†’ project almost scrapped
**Solution:** Every LLM call has 3-tier fallback

```python
async def extract_name_node(state: BookingState):
    """Extract customer name with 3-tier resilience."""
    try:
        # Tier 1: DSPy (best quality)
        name_extractor = NameExtractor()  # Your existing DSPy module
        result = await asyncio.wait_for(
            name_extractor(state["history"], state["message"]),
            timeout=5.0  # 5-second timeout
        )
        return {"extracted_data": {"first_name": result.first_name}}

    except (TimeoutError, ConnectionError) as e:
        # Tier 2: Pydantic validation + regex (fast, reliable)
        logger.warning(f"DSPy failed, using regex fallback: {e}")
        result = regex_name_extractor(state["message"])
        return {"extracted_data": {"first_name": result}}

    except Exception as e:
        # Tier 3: Graceful degradation (ask user)
        logger.error(f"All extraction failed: {e}")
        return {"response": "I didn't catch your name. Could you tell me again?"}
```

**Benefits:**

- âœ… Demo NEVER breaks (even if LLM offline)
- âœ… Degrades gracefully (quality drops, but system works)
- âœ… User experience unaffected (transparent fallbacks)
- âœ… Your junior's job saved

---

### 2. **Small Files (100 Lines Max)**

**Problem:** 1,043-line models.py, 674-line message_processor.py
**Solution:** Enforce via linter + code review

```
# .pylintrc (auto-enforce)
[FORMAT]
max-module-lines=100  # Hard limit
max-function-lines=50  # Hard limit per function
```

**File Size Targets:**

- Nodes: 50-100 lines (1 responsibility)
- Models: 30-50 lines (1 model per file)
- Utils: 30-50 lines (1 utility per file)
- Workflows: 100-150 lines (graph definition only)

---

### 3. **Visual + Code Workflows**

**Tool:** LangGraph Studio
**Features:**

- Drag-and-drop node editor
- Export graph â†’ Python code
- Import Python code â†’ visual graph
- Live execution visualization
- State inspection
- Breakpoints/debugging

**Example Workflow (Visual â†’ Code):**

```
[User Message]
    â†“
[Extract Name] â”€â”€â†’ [Extract Vehicle] â”€â”€â†’ [Extract Date]
    â†“ (if name missing)          â†“ (if vehicle missing)
[Ask for Name]                [Ask for Vehicle]
```

Exports to:

```python
workflow = StateGraph(BookingState)
workflow.add_node("extract_name", extract_name_node)
workflow.add_node("extract_vehicle", extract_vehicle_node)
workflow.add_conditional_edges("extract_name",
    lambda s: "extract_vehicle" if s["name"] else "ask_name")
```

---

### 4. **Async-First API**

**All nodes are async:**

```python
async def extract_name_node(state: BookingState) -> BookingState:
    """Async extraction with concurrent fallbacks."""
    tasks = [
        asyncio.create_task(dspy_extract_name(state)),  # DSPy (slow)
        asyncio.create_task(regex_extract_name(state))  # Regex (fast)
    ]

    # Return first successful result
    for task in asyncio.as_completed(tasks):
        try:
            result = await task
            if result:
                # Cancel other tasks
                for t in tasks:
                    t.cancel()
                return result
        except Exception:
            continue

    # All failed
    return {"error": "extraction_failed"}
```

**Benefits:**

- âœ… Faster responses (parallel execution)
- âœ… Non-blocking (handle multiple users)
- âœ… Better resource usage

---

### 5. **State = Single Source of Truth**

**No more scattered state!**

```python
from typing import TypedDict, Optional, Dict, List

class BookingState(TypedDict):
    """Single source of truth for booking workflow."""
    # Conversation
    conversation_id: str
    user_message: str
    history: List[Dict[str, str]]

    # Extracted Data (scratchpad replacement)
    customer: Optional[Dict[str, str]]  # first_name, last_name, phone
    vehicle: Optional[Dict[str, str]]   # brand, model, plate
    appointment: Optional[Dict[str, str]]  # date, service, slot

    # AI Analysis
    sentiment: Optional[Dict[str, float]]  # interest, anger, disgust, boredom
    intent: Optional[str]  # inquire, booking, pricing, complaint

    # Workflow Control
    current_step: str  # "extract_name", "confirm_booking", etc.
    completeness: float  # 0.0-1.0
    errors: List[str]

    # Response
    response: str
    should_confirm: bool
```

**LangGraph persists this automatically** with checkpointers:

```python
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = SqliteSaver("conversations.db")
app = workflow.compile(checkpointer=checkpointer)

# State auto-saved after EVERY node
# Resume from crash: app.invoke(state, thread_id="conv-123")
```

---

## ðŸ“‚ NEW FOLDER STRUCTURE

```
wapibot/
â”œâ”€â”€ workflows/                      # LangGraph workflow definitions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ booking_onetime.py         (100 lines) - One-time booking graph
â”‚   â”œâ”€â”€ booking_subscription.py    (120 lines) - Subscription booking graph
â”‚   â”œâ”€â”€ booking_emergency.py       (80 lines)  - Emergency service graph
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ state.py               (50 lines)  - BookingState TypedDict
â”‚       â””â”€â”€ routes.py              (60 lines)  - Conditional routing functions
â”‚
â”œâ”€â”€ nodes/                          # Workflow nodes (50-100 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extraction/                 # Data extraction nodes
â”‚   â”‚   â”œâ”€â”€ extract_name.py        (70 lines)  - Name extraction + fallback
â”‚   â”‚   â”œâ”€â”€ extract_vehicle.py     (80 lines)  - Vehicle extraction + fallback
â”‚   â”‚   â”œâ”€â”€ extract_date.py        (60 lines)  - Date extraction + fallback
â”‚   â”‚   â””â”€â”€ extract_phone.py       (65 lines)  - Phone extraction + fallback
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                   # AI analysis nodes
â”‚   â”‚   â”œâ”€â”€ analyze_sentiment.py   (75 lines)  - Sentiment + fallback
â”‚   â”‚   â””â”€â”€ classify_intent.py     (70 lines)  - Intent + fallback
â”‚   â”‚
â”‚   â”œâ”€â”€ responses/                  # Response generation nodes
â”‚   â”‚   â”œâ”€â”€ generate_response.py   (90 lines)  - LLM response + template
â”‚   â”‚   â””â”€â”€ compose_final.py       (85 lines)  - Final response assembly
â”‚   â”‚
â”‚   â”œâ”€â”€ booking/                    # Booking-specific nodes
â”‚   â”‚   â”œâ”€â”€ confirm_booking.py     (90 lines)  - Show confirmation
â”‚   â”‚   â”œâ”€â”€ create_service_request.py (100 lines) - ServiceRequest creation
â”‚   â”‚   â””â”€â”€ handle_edit.py         (70 lines)  - Handle edit action
â”‚   â”‚
â”‚   â””â”€â”€ validation/                 # Validation nodes
â”‚       â”œâ”€â”€ validate_completeness.py (60 lines) - Check required fields
â”‚       â””â”€â”€ detect_typos.py        (65 lines)  - Typo detection
â”‚
â”œâ”€â”€ models/                         # Pydantic models (30-50 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ customer.py                (40 lines)  - Customer, Name, Phone
â”‚   â”œâ”€â”€ vehicle.py                 (45 lines)  - Vehicle, VehicleBrandEnum
â”‚   â”œâ”€â”€ appointment.py             (35 lines)  - Appointment, Date, Slot
â”‚   â”œâ”€â”€ sentiment.py               (40 lines)  - SentimentScores
â”‚   â”œâ”€â”€ intent.py                  (30 lines)  - Intent, IntentClass
â”‚   â”œâ”€â”€ response.py                (45 lines)  - ChatResponse
â”‚   â””â”€â”€ service_request.py         (50 lines)  - ServiceRequest
â”‚
â”œâ”€â”€ dspy_modules/                   # Your existing DSPy modules (KEEP AS-IS)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extractors.py              (500 lines) - Name, Vehicle, Date, Phone extractors
â”‚   â”œâ”€â”€ analyzers.py               (300 lines) - Sentiment, Intent analyzers
â”‚   â”œâ”€â”€ generators.py              (200 lines) - Response generators
â”‚   â””â”€â”€ signatures.py              (400 lines) - All DSPy signatures
â”‚
â”œâ”€â”€ fallbacks/                      # Regex/rule-based fallbacks (30-50 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ name_fallback.py           (45 lines)  - Regex name extraction
â”‚   â”œâ”€â”€ vehicle_fallback.py        (50 lines)  - Regex vehicle extraction
â”‚   â”œâ”€â”€ date_fallback.py           (40 lines)  - Date parsing fallback
â”‚   â””â”€â”€ phone_fallback.py          (35 lines)  - Phone regex validation
â”‚
â”œâ”€â”€ api/                            # FastAPI routes (50-100 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    (100 lines) - FastAPI app setup
â”‚   â”œâ”€â”€ chat.py                    (80 lines)  - POST /chat endpoint
â”‚   â”œâ”€â”€ confirmation.py            (70 lines)  - POST /api/confirmation
â”‚   â””â”€â”€ webhooks.py                (90 lines)  - WhatsApp webhook
â”‚
â”œâ”€â”€ storage/                        # State persistence (50-80 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ checkpoints.py             (60 lines)  - LangGraph checkpoint config
â”‚   â”œâ”€â”€ conversations.py           (70 lines)  - Conversation storage
â”‚   â””â”€â”€ service_requests.py        (75 lines)  - ServiceRequest storage
â”‚
â”œâ”€â”€ utils/                          # Utilities (30-50 lines each)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ history.py                 (40 lines)  - History conversion
â”‚   â”œâ”€â”€ validators.py              (50 lines)  - Pydantic validators
â”‚   â””â”€â”€ logging.py                 (45 lines)  - Structured logging
â”‚
â””â”€â”€ config/                         # Configuration (30-50 lines each)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ settings.py                (50 lines)  - Pydantic Settings
    â”œâ”€â”€ llm.py                     (40 lines)  - LLM config (Ollama, OpenAI)
    â””â”€â”€ workflows.py               (45 lines)  - Workflow config
```

**Metrics:**

- Total files: ~60 files (vs current 50)
- Avg file size: **60 lines** (vs current 217 lines)
- Max file size: **120 lines** (vs current 1,043 lines)
- Largest reduction: `models.py` 1,043 â†’ 7 files Ã— 40 lines = **280 lines**

---

## ðŸ”„ WORKFLOW EXAMPLE: One-Time Booking

**File:** `workflows/booking_onetime.py` (100 lines)

```python
"""One-time car wash booking workflow with LLM resilience."""

from langgraph.graph import StateGraph, END
from workflows.shared.state import BookingState
from workflows.shared.routes import route_after_name, route_after_vehicle, route_after_date
from nodes.extraction import extract_name, extract_vehicle, extract_date, extract_phone
from nodes.analysis import analyze_sentiment, classify_intent
from nodes.responses import generate_response, compose_final
from nodes.booking import confirm_booking, create_service_request
from nodes.validation import validate_completeness


def create_onetime_booking_workflow() -> StateGraph:
    """Create one-time booking workflow graph."""

    # Initialize graph
    workflow = StateGraph(BookingState)

    # Add nodes
    workflow.add_node("analyze_sentiment", analyze_sentiment.node)
    workflow.add_node("classify_intent", classify_intent.node)
    workflow.add_node("extract_name", extract_name.node)
    workflow.add_node("extract_vehicle", extract_vehicle.node)
    workflow.add_node("extract_date", extract_date.node)
    workflow.add_node("extract_phone", extract_phone.node)
    workflow.add_node("validate_completeness", validate_completeness.node)
    workflow.add_node("confirm_booking", confirm_booking.node)
    workflow.add_node("create_service_request", create_service_request.node)
    workflow.add_node("generate_response", generate_response.node)
    workflow.add_node("compose_final", compose_final.node)

    # Define edges (flow control)
    workflow.set_entry_point("analyze_sentiment")
    workflow.add_edge("analyze_sentiment", "classify_intent")
    workflow.add_edge("classify_intent", "extract_name")

    # Conditional routing based on data completeness
    workflow.add_conditional_edges("extract_name", route_after_name)
    workflow.add_conditional_edges("extract_vehicle", route_after_vehicle)
    workflow.add_conditional_edges("extract_date", route_after_date)

    # Validation and confirmation
    workflow.add_edge("validate_completeness", "confirm_booking")
    workflow.add_conditional_edges(
        "confirm_booking",
        lambda s: "create_service_request" if s["should_confirm"] else "generate_response"
    )

    # Response generation
    workflow.add_edge("generate_response", "compose_final")
    workflow.add_edge("compose_final", END)
    workflow.add_edge("create_service_request", "compose_final")

    return workflow


# Compile workflow
from storage.checkpoints import get_checkpointer

onetime_booking_app = create_onetime_booking_workflow().compile(
    checkpointer=get_checkpointer("onetime_booking")
)
```

**Visual Representation (LangGraph Studio):**

```
[User Message]
    â†“
[Analyze Sentiment] â”€â”€â†’ [Classify Intent]
    â†“
[Extract Name] â”€â”€â†’ [Extract Phone] â”€â”€â†’ [Extract Vehicle] â”€â”€â†’ [Extract Date]
    â†“ (if missing name)         â†“ (if missing vehicle)
[Generate Response]          [Generate Response]
    â†“
[Validate Completeness]
    â†“
[Confirm Booking] â”€â”€â”¬â”€â”€â†’ [Create Service Request]
                    â””â”€â”€â†’ [Generate Response]
                          â†“
                    [Compose Final]
                          â†“
                        [END]
```

---

## ðŸ§© NODE EXAMPLE: Extract Name (with Resilience)

**File:** `nodes/extraction/extract_name.py` (70 lines)

```python
"""Extract customer name with 3-tier resilience."""

import asyncio
import logging
from typing import Dict, Any
from workflows.shared.state import BookingState
from dspy_modules.extractors import NameExtractor  # Your existing DSPy module
from fallbacks.name_fallback import RegexNameExtractor
from models.customer import Name

logger = logging.getLogger(__name__)

# Initialize extractors
dspy_extractor = NameExtractor()
regex_extractor = RegexNameExtractor()


async def extract_name_dspy(state: BookingState) -> Dict[str, Any]:
    """Tier 1: DSPy extraction (best quality)."""
    try:
        result = await asyncio.wait_for(
            dspy_extractor(state["history"], state["user_message"]),
            timeout=5.0
        )

        if result.first_name and result.first_name != "Unknown":
            logger.info(f"âœ… DSPy extracted name: {result.first_name}")
            return {
                "first_name": result.first_name,
                "last_name": result.last_name or "",
                "extraction_method": "dspy",
                "confidence": 0.95
            }
    except (TimeoutError, ConnectionError) as e:
        logger.warning(f"âš ï¸ DSPy timeout: {e}")
        raise
    except Exception as e:
        logger.error(f"âŒ DSPy failed: {e}")
        raise


async def extract_name_regex(state: BookingState) -> Dict[str, Any]:
    """Tier 2: Regex extraction (fast, reliable)."""
    result = regex_extractor.extract(state["user_message"])
    if result:
        logger.info(f"âœ… Regex extracted name: {result['first_name']}")
        return {**result, "extraction_method": "regex", "confidence": 0.70}
    raise ValueError("Regex extraction failed")


async def node(state: BookingState) -> BookingState:
    """
    Extract customer name with 3-tier fallback.

    Tier 1: DSPy (LLM-based, best quality)
    Tier 2: Regex (rule-based, fast)
    Tier 3: Ask user (graceful degradation)
    """

    # Try DSPy first
    try:
        name_data = await extract_name_dspy(state)
        state["customer"] = state.get("customer", {})
        state["customer"].update(name_data)
        state["current_step"] = "extract_phone"
        return state

    except Exception:
        # Try regex fallback
        try:
            name_data = await extract_name_regex(state)
            state["customer"] = state.get("customer", {})
            state["customer"].update(name_data)
            state["current_step"] = "extract_phone"
            return state

        except Exception:
            # Graceful degradation: ask user
            logger.warning("âš ï¸ All name extraction failed, asking user")
            state["response"] = "I didn't catch your name. What's your name?"
            state["current_step"] = "extract_name"  # Stay in same step
            state["errors"].append("name_extraction_failed")
            return state
```

**Benefits:**

- âœ… **70 lines** (vs 674 in message_processor.py)
- âœ… **Single responsibility** (SOLID principle)
- âœ… **3-tier resilience** (never crashes)
- âœ… **Async-first** (non-blocking)
- âœ… **Graceful degradation** (asks user if all fails)

---

## ðŸ›¡ï¸ FALLBACK EXAMPLE: Regex Name Extractor

**File:** `fallbacks/name_fallback.py` (45 lines)

```python
"""Regex-based name extraction fallback (when LLM fails)."""

import re
from typing import Optional, Dict

# Greeting stopwords (reject these as names)
STOPWORDS = {"hi", "hello", "hey", "haan", "yes", "ok", "okay", "sure"}


class RegexNameExtractor:
    """Fast, reliable name extraction using regex patterns."""

    # Patterns for name detection
    PATTERNS = [
        r"(?:my name is|i am|i'm|this is|call me)\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)",
        r"^([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)$",  # Just a capitalized name
    ]

    def extract(self, message: str) -> Optional[Dict[str, str]]:
        """
        Extract name using regex patterns.

        Returns:
            {"first_name": "John", "last_name": "Doe"} or None
        """
        message = message.strip()

        for pattern in self.PATTERNS:
            match = re.search(pattern, message, re.IGNORECASE)
            if match:
                full_name = match.group(1).strip()

                # Reject stopwords
                if full_name.lower() in STOPWORDS:
                    continue

                # Split into first/last
                parts = full_name.split()
                if len(parts) == 1:
                    return {"first_name": parts[0], "last_name": ""}
                else:
                    return {"first_name": parts[0], "last_name": " ".join(parts[1:])}

        return None
```

**Benefits:**

- âœ… **45 lines** (small, focused)
- âœ… **No LLM dependency** (works offline)
- âœ… **Fast** (<1ms vs 2-5s for LLM)
- âœ… **No regex hell** (clean Pydantic validation in models)

---

## ðŸ“Š MODELS EXAMPLE: Split from 1,043 Lines

**Before:** `datamodels/models.py` (1,043 lines with 44 models)

**After:** 7 files averaging 40 lines each

### `models/customer.py` (40 lines)

```python
"""Customer-related models."""

from pydantic import BaseModel, Field, validator
from typing import Optional


class Name(BaseModel):
    """Customer name with validation."""
    first_name: str = Field(..., min_length=1, max_length=50)
    last_name: Optional[str] = Field("", max_length=50)

    @validator("first_name")
    def validate_first_name(cls, v):
        """Ensure first name is not a greeting."""
        stopwords = {"hi", "hello", "hey", "haan", "yes"}
        if v.lower() in stopwords:
            raise ValueError(f"Invalid name: {v}")
        return v.title()


class Phone(BaseModel):
    """Indian phone number with validation."""
    number: str = Field(..., regex=r"^\+?91?[6-9]\d{9}$")

    @validator("number")
    def normalize_phone(cls, v):
        """Normalize to 10-digit format."""
        digits = re.sub(r"[^\d]", "", v)
        if len(digits) == 10:
            return digits
        elif len(digits) == 12 and digits.startswith("91"):
            return digits[2:]
        raise ValueError(f"Invalid phone: {v}")


class Customer(BaseModel):
    """Complete customer data."""
    name: Name
    phone: Phone
    email: Optional[str] = None
    address: Optional[str] = None
```

### `models/vehicle.py` (45 lines)

```python
"""Vehicle-related models."""

from pydantic import BaseModel, Field
from typing import Optional
from enum import Enum


class VehicleBrandEnum(str, Enum):
    """80+ vehicle brands (from your existing code)."""
    TOYOTA = "Toyota"
    HONDA = "Honda"
    MARUTI = "Maruti"
    HYUNDAI = "Hyundai"
    MAHINDRA = "Mahindra"
    TATA = "Tata"
    KIA = "Kia"
    # ... (rest of 80+ brands)


class Vehicle(BaseModel):
    """Vehicle details with validation."""
    brand: VehicleBrandEnum
    model: str = Field(..., min_length=1, max_length=50)
    plate: str = Field(..., regex=r"^[A-Z]{2}\d{2}[A-Z]{1,2}\d{4}$")
    vehicle_type: Optional[str] = Field(None, regex="^(hatchback|sedan|suv|luxury)$")

    @validator("plate")
    def normalize_plate(cls, v):
        """Normalize plate to uppercase without spaces."""
        return v.upper().replace(" ", "").replace("-", "")
```

**Benefits:**

- âœ… **1,043 lines â†’ 280 lines** (73% reduction)
- âœ… **Easy to navigate** (1 model = 1 file)
- âœ… **Pydantic validation** (no regex hell)
- âœ… **Type-safe** (mypy-compliant)

---

## ðŸš€ API EXAMPLE: FastAPI Endpoint

**File:** `api/chat.py` (80 lines)

```python
"""Chat endpoint using LangGraph workflow."""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from workflows.booking_onetime import onetime_booking_app
from workflows.shared.state import BookingState
from storage.conversations import get_conversation_history

router = APIRouter()


class ChatRequest(BaseModel):
    """Chat request payload."""
    conversation_id: str
    user_message: str


class ChatResponse(BaseModel):
    """Chat response payload."""
    message: str
    should_confirm: bool
    completeness: float
    extracted_data: dict
    service_request_id: str | None


@router.post("/chat", response_model=ChatResponse)
async def process_chat(request: ChatRequest):
    """
    Process user message through LangGraph booking workflow.

    Features:
    - Automatic LLM fallbacks (never crashes)
    - State persistence (resume after crash)
    - Async execution (non-blocking)
    """
    try:
        # Get conversation history
        history = await get_conversation_history(request.conversation_id)

        # Prepare state
        state: BookingState = {
            "conversation_id": request.conversation_id,
            "user_message": request.user_message,
            "history": history,
            "customer": None,
            "vehicle": None,
            "appointment": None,
            "sentiment": None,
            "intent": None,
            "current_step": "analyze_sentiment",
            "completeness": 0.0,
            "errors": [],
            "response": "",
            "should_confirm": False,
        }

        # Execute workflow (async, with automatic checkpointing)
        result = await onetime_booking_app.ainvoke(
            state,
            config={"configurable": {"thread_id": request.conversation_id}}
        )

        # Extract response
        return ChatResponse(
            message=result["response"],
            should_confirm=result["should_confirm"],
            completeness=result["completeness"],
            extracted_data={
                "customer": result.get("customer"),
                "vehicle": result.get("vehicle"),
                "appointment": result.get("appointment"),
            },
            service_request_id=result.get("service_request_id"),
        )

    except Exception as e:
        # Graceful error handling
        raise HTTPException(status_code=500, detail=str(e))
```

**Benefits:**

- âœ… **80 lines** (vs 490 in main.py)
- âœ… **Single responsibility** (just handle HTTP)
- âœ… **Async-first** (non-blocking)
- âœ… **LangGraph handles orchestration** (no 674-line process_message)

---

## ðŸŽ¨ VISUAL WORKFLOW EDITOR: LangGraph Studio

**Setup:**

```bash
# Install LangGraph Studio (desktop app)
pip install langgraph-studio

# Launch visual editor
langgraph-studio
```

**Features:**

1. **Drag-and-Drop Nodes**
   - Add node from library
   - Connect with edges
   - Set conditional routing

2. **Export to Code**

   ```python
   # Generated code from visual editor
   workflow = StateGraph(BookingState)
   workflow.add_node("extract_name", extract_name.node)
   workflow.add_node("extract_vehicle", extract_vehicle.node)
   workflow.add_conditional_edges("extract_name", route_after_name)
   ```

3. **Import from Code**
   - Paste your Python workflow
   - Auto-generates visual graph

4. **Live Execution**
   - Set breakpoints
   - Inspect state at each node
   - Step through execution
   - View logs in real-time

5. **State Visualization**

   ```
   Step 1: analyze_sentiment
   State: {"sentiment": {"interest": 7.5, "anger": 1.0}}

   Step 2: extract_name
   State: {"customer": {"first_name": "Ravi"}}

   Step 3: extract_vehicle
   State: {"vehicle": {"brand": "Honda", "model": "City"}}
   ```

**Benefits:**

- âœ… **Non-technical stakeholders** can understand workflow
- âœ… **Junior developer** can edit visually (no code)
- âœ… **Senior developer** can export to code for review
- âœ… **Product manager** can design flows in meetings

---

## ðŸ“ˆ COMPARISON: Before vs After

| Metric | Before (Your Code) | After (New Arch) | Improvement |
|--------|-------------------|------------------|-------------|
| **Largest file** | 1,043 lines (models.py) | 120 lines (workflows) | **87% smaller** |
| **Avg file size** | 217 lines | 60 lines | **72% smaller** |
| **Orchestration complexity** | 674 lines (message_processor) | 100 lines (workflow graph) | **85% reduction** |
| **LLM resilience** | 0% (crashes if Ollama fails) | 100% (3-tier fallbacks) | **âˆž% improvement** |
| **Visual editing** | None | LangGraph Studio | **Game changer** |
| **State management** | Scattered (3 places) | Single source (BookingState) | **Unified** |
| **Async support** | Partial | 100% async | **Better performance** |
| **File navigation** | 50 files, hard to find | 60 files, intuitive structure | **Better DX** |

---

## ðŸŽ¯ MIGRATION PLAN

### Phase 1: Foundation (Week 1)

- [x] Design architecture (this document)
- [ ] Create folder structure
- [ ] Split models.py â†’ 7 files
- [ ] Define BookingState TypedDict
- [ ] Setup LangGraph + checkpoints

### Phase 2: Nodes (Week 2-3)

- [ ] Extract existing DSPy modules to dspy_modules/
- [ ] Create extraction nodes with 3-tier fallbacks
- [ ] Create analysis nodes (sentiment, intent)
- [ ] Create response generation nodes
- [ ] Create booking nodes (confirm, create service request)

### Phase 3: Workflows (Week 4)

- [ ] Build one-time booking workflow
- [ ] Test with LangGraph Studio
- [ ] Add conditional routing
- [ ] Setup state persistence

### Phase 4: API (Week 5)

- [ ] Migrate /chat endpoint
- [ ] Migrate /api/confirmation endpoint
- [ ] Add error handling
- [ ] Load testing

### Phase 5: Production (Week 6)

- [ ] Deploy to staging
- [ ] Run E2E tests
- [ ] Performance tuning
- [ ] Deploy to production

**Total Time:** 6 weeks (vs 36 hours of hell in V1)

---

## ðŸ›¡ï¸ RESILIENCE GUARANTEES

### 1. **LLM Offline Protection**

```python
# Every node has this structure:
async def node(state):
    try:
        return await dspy_module(state)  # Try LLM
    except:
        return await fallback(state)  # Use regex/rules
```

### 2. **Timeout Protection**

```python
# All LLM calls have 5-second timeout
result = await asyncio.wait_for(llm_call(), timeout=5.0)
```

### 3. **State Persistence**

```python
# Crash recovery: Resume from last checkpoint
app.invoke(state, thread_id="conv-123")
```

### 4. **Graceful Degradation**

```python
# If all extraction fails, ask user directly
state["response"] = "Could you tell me your name again?"
```

---

## ðŸ”§ DEVELOPMENT WORKFLOW

### Local Development

```bash
# Start Ollama (optional, with fallbacks)
ollama serve

# Start FastAPI dev server
uvicorn api.main:app --reload --port 8000

# Launch LangGraph Studio (visual editor)
langgraph-studio
```

### Code Review Checklist

- [ ] File size â‰¤ 100 lines?
- [ ] Single responsibility (SOLID)?
- [ ] Has LLM fallback?
- [ ] Async function?
- [ ] Type hints?
- [ ] Docstring?
- [ ] Unit test?

### CI/CD Pipeline

```yaml
# .github/workflows/ci.yml
- name: Check file sizes
  run: |
    max_lines=$(find . -name "*.py" -exec wc -l {} + | awk '{print $1}' | sort -rn | head -1)
    if [ $max_lines -gt 100 ]; then
      echo "File exceeds 100 lines!"
      exit 1
    fi
```

---

## ðŸ“š NEXT STEPS

1. **Review this document** with team
2. **Approve architecture** or request changes
3. **Start Phase 1** (foundation)
4. **Weekly demos** (show progress to stakeholders)
5. **Migrate to production** (6 weeks)

---

## âœ… SUCCESS CRITERIA

- âœ… **No file >100 lines**
- âœ… **System works when Ollama offline**
- âœ… **Visual workflow editor works**
- âœ… **Async API handles 100+ concurrent users**
- âœ… **Subscription workflow added in 1 day**
- âœ… **Junior can edit workflows visually**
- âœ… **Senior can review generated code**
- âœ… **Demos NEVER break**

---

**Status:** Ready for approval
**Next:** Team review meeting
